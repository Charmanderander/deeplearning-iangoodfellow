## Machine Learning Basics

>> A computer program is said to learn from experince E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P improves with experience E

## 1.Learning Algorithms

Task T: Classification, Regression, Transcription, Machine Translation, Structured Output, Anomaly Detection, Synthesis and Sampling, Imputation of missing values, Denoising, Density Estimation

Performance P: Accuracy, Precision, Recall, AUC, F-score, RMSE ...

Experience E: Unsupervised, Supervised, Reinforcement Learning

## 2. Capacity, Overfitting, Underfitting

The central challenge in machine learning is making it **generalizable** to unseen datasets

In the data generation process, **i.i.d Assumption** assumes that the datasets are independent, and identically distributed

Underfitting occurs when the model is not able to obtain a sufficiently low error on the training set

Overfitting occurs when the difference between the training error and testing error is high

We can control a model's tendency to over/underfit by changing it's capacity.

A model's capacity is it's ability to fit a wide variety of functions.

Models with low capacity may struggle to fit the training set, while models with high capacity can overfit the training set by memorizing the properties of the training set that may not be present in the test set.

One way to control the model's capacity is to choose it's **hypothesis space**, which is the set of functions that the model is allowed to select as being the solution

>> Example: In linear regression, we can increase the capcity by allowing it to include polynomials, rather than just linear functions.

**Models perform best when their capcity approximately captures the complexity of the task they need to perform**

Other than changing the amount of input features and adding new parameters to those features, we can change the capacity by allowing the model to choose which family of functions to choose from. This is called **representational capacity**.

## 2.1 No Free Lunch Theorem

The No Free Lunch Theorem states that averaged over all possible data-generating distributions, every classification algorithm has the same error rate when classifying previously unobserved points. 

In other words, no machine learning algorithm is universally better than the other.

But fortunately, machine learning research does not seek a universial learning algorithm (yet), but is only applied to local problems.

## 2.2 Regularization

One method of modifying a learning algorthim is to increase or decrease the model's representational capacity by adding or removing functions from the hypothesis space.

Another way of modifying is to include a weight decay, or a **regularizer** as a penalty to the cost function. A larger regularizer forces the weights to become smaller.

Regularization reduces generalization error, without reducing training error.

## 3. Hyperparameters and Validation Sets

Hyperparameters are used to control the model's behavior.

If the model solely learns on the training set, the hyperparameters chosen will be those that maximize the the training score, which can result in overfitting.

One way to combat this is to have a **validation set**, which is a fraction of the training set that is not used for training, but for testing the model's performance.

No data from the test set should be used in the validation set as well. This will lead to data leakage.

## 3.1 Cross Validation

To avoid any bad splits when doing validation, we choose different segments of the training set to be the validation set, and we average the performance across each set.

K-fold cross validation chooses `K` number of non-overlapping segments from the training set.

## 4. Estimators, Bias and Variance

**Point Estimation** involves the use of sample data to calculate a single value (known as a point estimate or statistic) which is to serve as a "best guess" or "best estimate" of an unknown population parameter

Point Estimation can also refer to the relationship between input and target variables. We call that **Function Estimation**
 
The **Bias** of an estimator is the difference between the estimator's expected value and the true value of the parameter being estimated. Having a low bias is often (but not always) preferred. A low bias would mean the expected value and true value are close to each other.
 
The **Variance** of an estimator is how much the estimator varies as we randomly resample data points from the same data generator. Having low variance is preferred, as we want the estimator to have consistent results. The **Standard Error** is the square root of the Variance.
 
There is the important component of **Bias-Variance** trade off. Bias and Variance measures two different sources of errors in the estimator. Bias measures expected deviation from the true value. Variance measures measures the deviation from the expected estimator values over various data samples from the same data generator.
 
 The most common trade-off is to use cross-validation. We can also use **Mean Squared Error (MSE)**
 
 The MSE measures the overall expected deviations between the estimator and the true value of the parameter. Evaluating the MSE takes into account both bias and variance, thus when we minimize MSE, we implicitly optimize bias and variance
 
 **Strong Consistency** states that as the training set increases, the estimator converges to the true value of the parameter. Consistency ensures that the bias in the estimator diminishes as the training set grows.
 
 ## 5. Maximum Likelihood Estimation
